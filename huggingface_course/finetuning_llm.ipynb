{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6e32e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (25.1.1)\n",
      "Requirement already satisfied: datasets in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: filelock in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (2.2.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->datasets) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/Works/Practice/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing the packages\n",
    "!pip install --upgrade pip\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99d9129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968728f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'However , EPA officials would not confirm the 20 percent figure .',\n",
       " 'sentence2': 'Only in the past few weeks have officials settled on the 20 percent figure .',\n",
       " 'label': 0,\n",
       " 'idx': 812}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Signle dataset from the train split\n",
    "raw_dataset[\"validation\"][87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3ae89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features of the datase\n",
    "raw_dataset[\"test\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f415f6a",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdfb1b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1555e4fd864939916bcad37c43614b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login() # You will be prompted for your HF key, which will then be saved locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3788b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence_1 = tokenizer(raw_dataset[\"train\"][\"sentence1\"])\n",
    "tokenized_sentence_2 = tokenizer(raw_dataset[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc865666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 24049, 2001, 2087, 3728, 3026, 3580, 2343, 2005, 1996, 9722, 1004, 4132, 9340, 12439, 2964, 2449, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [101, 3026, 3580, 2343, 4388, 24049, 1010, 3839, 2132, 1997, 1996, 9722, 1998, 4132, 9340, 12439, 2964, 3131, 1010, 2097, 2599, 1996, 2047, 9178, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input = tokenizer(raw_dataset[\"train\"][15][\"sentence1\"])\n",
    "input2 = tokenizer(raw_dataset[\"train\"][15][\"sentence2\"])\n",
    "print(input)\n",
    "print(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61622eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 24049, 2001, 2087, 3728, 3026, 3580, 2343, 2005, 1996, 9722, 1004, 4132, 9340, 12439, 2964, 2449, 1012, 102, 3026, 3580, 2343, 4388, 24049, 1010, 3839, 2132, 1997, 1996, 9722, 1998, 4132, 9340, 12439, 2964, 3131, 1010, 2097, 2599, 1996, 2047, 9178, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(raw_dataset[\"train\"][15][\"sentence1\"],raw_dataset[\"train\"][15][\"sentence2\"])\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf922d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'rudder',\n",
       " 'was',\n",
       " 'most',\n",
       " 'recently',\n",
       " 'senior',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'for',\n",
       " 'the',\n",
       " 'developer',\n",
       " '&',\n",
       " 'platform',\n",
       " 'evan',\n",
       " '##gel',\n",
       " '##ism',\n",
       " 'business',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'senior',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'eric',\n",
       " 'rudder',\n",
       " ',',\n",
       " 'formerly',\n",
       " 'head',\n",
       " 'of',\n",
       " 'the',\n",
       " 'developer',\n",
       " 'and',\n",
       " 'platform',\n",
       " 'evan',\n",
       " '##gel',\n",
       " '##ism',\n",
       " 'unit',\n",
       " ',',\n",
       " 'will',\n",
       " 'lead',\n",
       " 'the',\n",
       " 'new',\n",
       " 'entity',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45b150c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize funtion for batch processing\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed332af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .',\n",
       " 'sentence2': 'PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .',\n",
       " 'label': 1,\n",
       " 'idx': 4,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  4518,\n",
       "  3123,\n",
       "  1002,\n",
       "  1016,\n",
       "  1012,\n",
       "  2340,\n",
       "  1010,\n",
       "  2030,\n",
       "  2055,\n",
       "  2340,\n",
       "  3867,\n",
       "  1010,\n",
       "  2000,\n",
       "  2485,\n",
       "  5958,\n",
       "  2012,\n",
       "  1002,\n",
       "  2538,\n",
       "  1012,\n",
       "  4868,\n",
       "  2006,\n",
       "  1996,\n",
       "  2047,\n",
       "  2259,\n",
       "  4518,\n",
       "  3863,\n",
       "  1012,\n",
       "  102,\n",
       "  18720,\n",
       "  1004,\n",
       "  1041,\n",
       "  13058,\n",
       "  1012,\n",
       "  6661,\n",
       "  5598,\n",
       "  1002,\n",
       "  1015,\n",
       "  1012,\n",
       "  6191,\n",
       "  2030,\n",
       "  1022,\n",
       "  3867,\n",
       "  2000,\n",
       "  1002,\n",
       "  2538,\n",
       "  1012,\n",
       "  6021,\n",
       "  2006,\n",
       "  1996,\n",
       "  2047,\n",
       "  2259,\n",
       "  4518,\n",
       "  3863,\n",
       "  2006,\n",
       "  5958,\n",
       "  1012,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset =  raw_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset[\"train\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0c3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc5f7a",
   "metadata": {},
   "source": [
    "Observe different input ids length after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c9d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [1, 0, 1, 0, 1, 1, 0, 1], 'input_ids': [[101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102, 7727, 2000, 2032, 2004, 2069, 1000, 1996, 7409, 1000, 1010, 2572, 3217, 5831, 5496, 2010, 2567, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102], [101, 9805, 3540, 11514, 2050, 3079, 11282, 2243, 1005, 1055, 2077, 4855, 1996, 4677, 2000, 3647, 4576, 1999, 2687, 2005, 1002, 1016, 1012, 1019, 4551, 1012, 102, 9805, 3540, 11514, 2050, 4149, 11282, 2243, 1005, 1055, 1999, 2786, 2005, 1002, 6353, 2509, 2454, 1998, 2853, 2009, 2000, 3647, 4576, 2005, 1002, 1015, 1012, 1022, 4551, 1999, 2687, 1012, 102], [101, 2027, 2018, 2405, 2019, 15147, 2006, 1996, 4274, 2006, 2238, 2184, 1010, 5378, 1996, 6636, 2005, 5096, 1010, 2002, 2794, 1012, 102, 2006, 2238, 2184, 1010, 1996, 2911, 1005, 1055, 5608, 2018, 2405, 2019, 15147, 2006, 1996, 4274, 1010, 5378, 1996, 14792, 2005, 5096, 1012, 102], [101, 2105, 6021, 19481, 13938, 2102, 1010, 21628, 6661, 2020, 2039, 2539, 16653, 1010, 2030, 1018, 1012, 1018, 1003, 1010, 2012, 1037, 1002, 1018, 1012, 5179, 1010, 2383, 3041, 2275, 1037, 2501, 2152, 1997, 1037, 1002, 1018, 1012, 5401, 1012, 102, 21628, 6661, 5598, 2322, 16653, 1010, 2030, 1018, 1012, 1020, 1003, 1010, 2000, 2275, 1037, 2501, 5494, 2152, 2012, 1037, 1002, 1018, 1012, 5401, 1012, 102], [101, 1996, 4518, 3123, 1002, 1016, 1012, 2340, 1010, 2030, 2055, 2340, 3867, 1010, 2000, 2485, 5958, 2012, 1002, 2538, 1012, 4868, 2006, 1996, 2047, 2259, 4518, 3863, 1012, 102, 18720, 1004, 1041, 13058, 1012, 6661, 5598, 1002, 1015, 1012, 6191, 2030, 1022, 3867, 2000, 1002, 2538, 1012, 6021, 2006, 1996, 2047, 2259, 4518, 3863, 2006, 5958, 1012, 102], [101, 6599, 1999, 1996, 2034, 4284, 1997, 1996, 2095, 3333, 2321, 3867, 2013, 1996, 2168, 2558, 1037, 2095, 3041, 1012, 102, 2007, 1996, 9446, 5689, 2058, 5954, 1005, 1055, 2194, 1010, 6599, 1996, 2034, 4284, 1997, 1996, 2095, 3333, 2321, 3867, 2013, 1996, 2168, 2558, 1037, 2095, 3041, 1012, 102], [101, 1996, 17235, 2850, 4160, 2018, 1037, 4882, 5114, 1997, 2459, 1012, 2676, 1010, 2030, 1015, 1012, 1016, 3867, 1010, 5494, 2012, 1015, 1010, 19611, 1012, 2321, 2006, 5958, 1012, 102, 1996, 6627, 1011, 17958, 17235, 2850, 4160, 12490, 1012, 11814, 2594, 24356, 2382, 1012, 4805, 2685, 1010, 2030, 1016, 1012, 5840, 3867, 1010, 2000, 1015, 1010, 19611, 1012, 2321, 1012, 102], [101, 1996, 4966, 1011, 10507, 2050, 2059, 12068, 2000, 1996, 2110, 4259, 2457, 1012, 102, 1996, 4966, 10507, 2050, 12068, 2008, 3247, 2000, 1996, 1057, 1012, 1055, 1012, 4259, 2457, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "[50, 59, 47, 67, 59, 50, 62, 32]\n"
     ]
    }
   ],
   "source": [
    "samples = tokenized_dataset[\"train\"][:8]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "print(samples)\n",
    "\n",
    "ids_len = [len(ids) for ids in samples[\"input_ids\"]]\n",
    "print(ids_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8579a6",
   "metadata": {},
   "source": [
    "Now see how collator fix this variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc1b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d924e3",
   "metadata": {},
   "source": [
    "### initializing the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197e1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7679b",
   "metadata": {},
   "source": [
    "### Load the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd5cb411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5212ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset= tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    # tokenizer=tokenizer,      #deprecated\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e66c8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 00:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.38053408687151075, metrics={'train_runtime': 55.0265, 'train_samples_per_second': 199.976, 'train_steps_per_second': 25.024, 'total_flos': 405114969714960.0, 'train_loss': 0.38053408687151075, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f772f9",
   "metadata": {},
   "source": [
    "### Basic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742231d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/51 00:00 < 00:00, 75.78 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1732cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.7865925 ,  3.3046844 ],\n",
       "       [ 2.5662029 , -2.8894274 ],\n",
       "       [ 1.0556097 , -0.81592697],\n",
       "       [-2.6189976 ,  3.0776405 ],\n",
       "       [ 2.3464227 , -2.8323061 ],\n",
       "       [-2.649227  ,  3.1177146 ],\n",
       "       [-2.6901915 ,  3.1795273 ],\n",
       "       [-2.6955612 ,  3.214234  ],\n",
       "       [-2.673455  ,  3.1229036 ],\n",
       "       [-2.6811433 ,  3.1904345 ],\n",
       "       [-2.7087827 ,  3.2445984 ],\n",
       "       [ 2.5615673 , -2.93583   ],\n",
       "       [ 2.706623  , -2.9594216 ],\n",
       "       [-2.7448473 ,  3.161352  ],\n",
       "       [-2.8113616 ,  3.3501692 ],\n",
       "       [ 0.8412137 , -0.7337403 ],\n",
       "       [-2.8029342 ,  3.3453996 ],\n",
       "       [ 0.25675583,  0.16048515],\n",
       "       [-2.852763  ,  3.38552   ],\n",
       "       [ 1.7327303 , -1.9107269 ],\n",
       "       [ 2.3028345 , -2.7093072 ],\n",
       "       [-2.5352528 ,  2.952558  ],\n",
       "       [ 2.56475   , -2.9771361 ],\n",
       "       [-2.844524  ,  3.3269508 ],\n",
       "       [-2.773433  ,  3.2944746 ],\n",
       "       [-1.7231929 ,  2.1131    ],\n",
       "       [-2.0153131 ,  2.3776257 ],\n",
       "       [-2.814791  ,  3.3407087 ],\n",
       "       [-2.6625237 ,  3.1010215 ],\n",
       "       [-2.7579935 ,  3.2503724 ],\n",
       "       [-1.9055463 ,  2.2742124 ],\n",
       "       [-2.817943  ,  3.3523188 ],\n",
       "       [-2.4246378 ,  2.7755635 ],\n",
       "       [-2.6831121 ,  3.1729054 ],\n",
       "       [-2.6888268 ,  3.2159832 ],\n",
       "       [-2.6213362 ,  3.061689  ],\n",
       "       [ 2.7544732 , -3.0468054 ],\n",
       "       [ 2.784635  , -2.8948472 ],\n",
       "       [-1.8390021 ,  2.2043338 ],\n",
       "       [-2.7967    ,  3.3237312 ],\n",
       "       [ 2.6367006 , -3.0479555 ],\n",
       "       [-2.631899  ,  3.125374  ],\n",
       "       [ 1.4212139 , -1.7452177 ],\n",
       "       [ 2.3568926 , -2.8195174 ],\n",
       "       [-2.2550583 ,  2.6083553 ],\n",
       "       [-2.7064624 ,  3.1855717 ],\n",
       "       [-2.742432  ,  3.226143  ],\n",
       "       [ 2.189735  , -2.6822655 ],\n",
       "       [-2.6429875 ,  3.122745  ],\n",
       "       [-2.703823  ,  3.1775353 ],\n",
       "       [-2.6219573 ,  3.0642118 ],\n",
       "       [-2.6152732 ,  3.0825963 ],\n",
       "       [-2.5404427 ,  3.031301  ],\n",
       "       [-2.689209  ,  3.1878123 ],\n",
       "       [-2.750738  ,  3.247554  ],\n",
       "       [-2.5721834 ,  3.043175  ],\n",
       "       [-1.6759472 ,  2.1227808 ],\n",
       "       [-2.80721   ,  3.3335433 ],\n",
       "       [-2.697446  ,  3.2143493 ],\n",
       "       [-2.6809456 ,  3.167797  ],\n",
       "       [-2.1699378 ,  2.546887  ],\n",
       "       [ 2.2690902 , -2.7781668 ],\n",
       "       [-2.6752675 ,  3.1680698 ],\n",
       "       [-2.4586546 ,  2.8628824 ],\n",
       "       [-2.645868  ,  3.1239693 ],\n",
       "       [ 2.541604  , -2.9205515 ],\n",
       "       [-2.8408554 ,  3.3842013 ],\n",
       "       [-2.810866  ,  3.3338318 ],\n",
       "       [-1.8305669 ,  2.0737    ],\n",
       "       [-2.7538517 ,  3.280519  ],\n",
       "       [-2.7505245 ,  3.2723882 ],\n",
       "       [-1.5963224 ,  2.0172527 ],\n",
       "       [-2.704072  ,  3.2057152 ],\n",
       "       [-2.6136305 ,  3.1105003 ],\n",
       "       [-2.4759984 ,  2.894604  ],\n",
       "       [-2.5076742 ,  3.0092964 ],\n",
       "       [-2.3574448 ,  2.7871642 ],\n",
       "       [-2.823153  ,  3.3446083 ],\n",
       "       [-2.7087634 ,  3.1991951 ],\n",
       "       [-2.6257024 ,  3.1059856 ],\n",
       "       [-2.5780787 ,  2.9775414 ],\n",
       "       [-2.7748168 ,  3.3073316 ],\n",
       "       [-2.8047073 ,  3.3236747 ],\n",
       "       [ 2.3761904 , -2.8114731 ],\n",
       "       [-2.6653225 ,  3.1792114 ],\n",
       "       [ 0.5184179 , -0.3415091 ],\n",
       "       [-2.5859234 ,  3.0163915 ],\n",
       "       [ 1.1054499 , -1.1788207 ],\n",
       "       [-2.6749592 ,  3.1587744 ],\n",
       "       [-2.850513  ,  3.3945801 ],\n",
       "       [ 1.8105996 , -2.1069114 ],\n",
       "       [-2.694237  ,  3.1617572 ],\n",
       "       [-2.6596375 ,  3.1834683 ],\n",
       "       [-2.8038383 ,  3.3523157 ],\n",
       "       [-2.7702856 ,  3.2958996 ],\n",
       "       [-2.6887763 ,  3.227349  ],\n",
       "       [ 2.3317184 , -2.728245  ],\n",
       "       [-2.6756308 ,  3.1327536 ],\n",
       "       [-2.7098029 ,  3.2357917 ],\n",
       "       [-2.628646  ,  3.0657706 ],\n",
       "       [-2.771715  ,  3.2920291 ],\n",
       "       [-2.6054251 ,  3.0537484 ],\n",
       "       [-2.661005  ,  3.101567  ],\n",
       "       [-2.743856  ,  3.2632484 ],\n",
       "       [ 1.8178028 , -2.340259  ],\n",
       "       [-2.715995  ,  3.2222798 ],\n",
       "       [-2.6537828 ,  3.0828247 ],\n",
       "       [ 2.7388568 , -2.9462492 ],\n",
       "       [ 1.4705772 , -1.5215842 ],\n",
       "       [-2.6894524 ,  3.1649852 ],\n",
       "       [ 1.7480589 , -2.1600714 ],\n",
       "       [-2.7931144 ,  3.2615497 ],\n",
       "       [-2.725675  ,  3.2378016 ],\n",
       "       [-2.8247528 ,  3.3650987 ],\n",
       "       [-2.6276672 ,  3.0707219 ],\n",
       "       [ 0.9169792 , -0.98256695],\n",
       "       [-2.787877  ,  3.3222458 ],\n",
       "       [-2.6323307 ,  3.036161  ],\n",
       "       [-2.797657  ,  3.3239803 ],\n",
       "       [-2.7870603 ,  3.2893543 ],\n",
       "       [-2.715064  ,  3.169721  ],\n",
       "       [-0.9376635 ,  1.3158898 ],\n",
       "       [ 1.7250925 , -2.0754867 ],\n",
       "       [-2.7732468 ,  3.22798   ],\n",
       "       [-2.7850368 ,  3.3189104 ],\n",
       "       [-2.7592165 ,  3.283399  ],\n",
       "       [-2.6869178 ,  3.132539  ],\n",
       "       [ 2.1613364 , -2.6805997 ],\n",
       "       [-2.8495185 ,  3.387363  ],\n",
       "       [-2.681772  ,  3.142818  ],\n",
       "       [-2.653163  ,  3.12393   ],\n",
       "       [ 0.16789757, -0.01551992],\n",
       "       [-2.641601  ,  3.0598817 ],\n",
       "       [ 2.0229177 , -2.4463456 ],\n",
       "       [-2.3694096 ,  2.7825506 ],\n",
       "       [-2.6780717 ,  3.1682773 ],\n",
       "       [ 1.924236  , -2.2239213 ],\n",
       "       [ 2.6937132 , -2.9083958 ],\n",
       "       [-2.8605661 ,  3.3934321 ],\n",
       "       [-2.739848  ,  3.2352273 ],\n",
       "       [-2.7926407 ,  3.3227372 ],\n",
       "       [ 0.3521068 , -0.58645594],\n",
       "       [ 2.5053961 , -2.7807016 ],\n",
       "       [-2.7275898 ,  3.18186   ],\n",
       "       [ 2.4390736 , -2.848877  ],\n",
       "       [-0.9234535 ,  1.246111  ],\n",
       "       [-2.8041031 ,  3.3318949 ],\n",
       "       [-2.3682718 ,  2.7714345 ],\n",
       "       [ 1.6159412 , -1.8528115 ],\n",
       "       [-2.710497  ,  3.2015676 ],\n",
       "       [ 2.5847023 , -2.8633463 ],\n",
       "       [-2.6629682 ,  3.1322684 ],\n",
       "       [-1.9433919 ,  2.2794187 ],\n",
       "       [-2.812402  ,  3.3267782 ],\n",
       "       [-2.0534458 ,  2.3944678 ],\n",
       "       [-2.7273805 ,  3.215155  ],\n",
       "       [-2.573041  ,  3.0586264 ],\n",
       "       [-2.5961611 ,  3.051422  ],\n",
       "       [ 1.9415766 , -2.2967486 ],\n",
       "       [-2.606801  ,  3.0855408 ],\n",
       "       [-2.467237  ,  2.9298646 ],\n",
       "       [-2.7192059 ,  3.1955817 ],\n",
       "       [-2.7960687 ,  3.3275764 ],\n",
       "       [-2.7497733 ,  3.2423885 ],\n",
       "       [-2.728565  ,  3.2303326 ],\n",
       "       [-2.7170045 ,  3.209296  ],\n",
       "       [-1.5272962 ,  1.9447207 ],\n",
       "       [ 1.9668369 , -2.6347103 ],\n",
       "       [-2.744086  ,  3.2543876 ],\n",
       "       [ 2.496736  , -2.774469  ],\n",
       "       [ 1.2995842 , -1.2615418 ],\n",
       "       [ 2.7237635 , -2.873251  ],\n",
       "       [ 0.8573865 , -0.56340086],\n",
       "       [-2.6612751 ,  3.1252115 ],\n",
       "       [-2.561622  ,  3.0403826 ],\n",
       "       [-2.6639848 ,  3.1513772 ],\n",
       "       [-2.7299383 ,  3.2175531 ],\n",
       "       [ 1.3929142 , -1.6415069 ],\n",
       "       [-2.7866645 ,  3.3092196 ],\n",
       "       [-2.7390356 ,  3.2471428 ],\n",
       "       [-1.9815918 ,  2.3508189 ],\n",
       "       [-2.5251734 ,  2.9603782 ],\n",
       "       [-2.8353243 ,  3.350838  ],\n",
       "       [-2.7618074 ,  3.284617  ],\n",
       "       [-2.6431284 ,  2.9940069 ],\n",
       "       [-2.8425062 ,  3.3415232 ],\n",
       "       [ 2.2919965 , -2.6087818 ],\n",
       "       [-2.3577943 ,  2.7133272 ],\n",
       "       [ 2.0115411 , -2.5731218 ],\n",
       "       [-2.677536  ,  3.1280978 ],\n",
       "       [-2.7794816 ,  3.292326  ],\n",
       "       [ 2.155553  , -2.5202532 ],\n",
       "       [ 1.1053166 , -0.9860983 ],\n",
       "       [-2.8405282 ,  3.3476312 ],\n",
       "       [-2.2838364 ,  2.6788788 ],\n",
       "       [-2.3848758 ,  2.8343596 ],\n",
       "       [-2.8455641 ,  3.3730083 ],\n",
       "       [-1.6280024 ,  2.0396626 ],\n",
       "       [-2.627324  ,  3.1115959 ],\n",
       "       [-2.6592402 ,  3.128282  ],\n",
       "       [-2.5717292 ,  3.0141397 ],\n",
       "       [-2.5781338 ,  2.990424  ],\n",
       "       [-2.0873756 ,  2.4824092 ],\n",
       "       [-2.6226318 ,  3.1290863 ],\n",
       "       [-2.592278  ,  3.065297  ],\n",
       "       [ 2.0750952 , -2.508107  ],\n",
       "       [-2.612391  ,  3.1073322 ],\n",
       "       [-2.5878437 ,  3.053094  ],\n",
       "       [ 2.24195   , -2.5905762 ],\n",
       "       [-0.9950196 ,  1.3562148 ],\n",
       "       [-2.1402745 ,  2.5363042 ],\n",
       "       [-2.809598  ,  3.3149364 ],\n",
       "       [-2.369825  ,  2.7318563 ],\n",
       "       [ 2.4831545 , -2.8409526 ],\n",
       "       [-2.7507844 ,  3.2280924 ],\n",
       "       [-2.8046567 ,  3.3376553 ],\n",
       "       [-2.6677752 ,  3.0904777 ],\n",
       "       [-2.7737005 ,  3.2910917 ],\n",
       "       [ 2.7485    , -2.947056  ],\n",
       "       [-2.6394918 ,  3.0689821 ],\n",
       "       [-2.0409162 ,  2.3995116 ],\n",
       "       [-2.813182  ,  3.2907627 ],\n",
       "       [-2.7728207 ,  3.2944884 ],\n",
       "       [ 2.1907287 , -2.5024514 ],\n",
       "       [-2.6431875 ,  3.157631  ],\n",
       "       [-2.7463195 ,  3.2758677 ],\n",
       "       [-2.7737408 ,  3.292837  ],\n",
       "       [-2.5718222 ,  2.989345  ],\n",
       "       [-2.6241097 ,  3.0799682 ],\n",
       "       [-2.2993872 ,  2.6897418 ],\n",
       "       [-2.7145743 ,  3.2473211 ],\n",
       "       [-2.7038786 ,  3.1943285 ],\n",
       "       [ 0.4221049 , -0.1857511 ],\n",
       "       [ 2.6902487 , -2.8949957 ],\n",
       "       [ 1.846615  , -2.2326782 ],\n",
       "       [ 0.18609802, -0.19931956],\n",
       "       [-2.500213  ,  2.9756546 ],\n",
       "       [ 2.6107776 , -2.9816947 ],\n",
       "       [-2.2784915 ,  2.6107445 ],\n",
       "       [-2.4363976 ,  2.8327827 ],\n",
       "       [-2.6685755 ,  3.067212  ],\n",
       "       [ 2.44307   , -2.838827  ],\n",
       "       [-1.7463143 ,  2.1226459 ],\n",
       "       [-2.3088102 ,  2.6979523 ],\n",
       "       [-2.798952  ,  3.303148  ],\n",
       "       [-2.6981797 ,  3.180348  ],\n",
       "       [-2.6636248 ,  3.179797  ],\n",
       "       [ 1.8924415 , -2.2728083 ],\n",
       "       [-2.6616004 ,  3.1707222 ],\n",
       "       [-1.9865848 ,  2.366068  ],\n",
       "       [-2.5521164 ,  3.029351  ],\n",
       "       [ 2.2353754 , -2.5799692 ],\n",
       "       [ 2.164588  , -2.4637926 ],\n",
       "       [-2.27203   ,  2.6619644 ],\n",
       "       [ 1.7314678 , -1.9738488 ],\n",
       "       [ 2.5407321 , -2.7885559 ],\n",
       "       [-2.6430645 ,  3.1661305 ],\n",
       "       [-2.7910593 ,  3.3165433 ],\n",
       "       [-2.6939814 ,  3.1801836 ],\n",
       "       [-1.4388714 ,  1.8352195 ],\n",
       "       [-2.6984293 ,  3.2067864 ],\n",
       "       [-1.3820634 ,  1.754207  ],\n",
       "       [-2.7551937 ,  3.2342079 ],\n",
       "       [-1.0767515 ,  1.2957    ],\n",
       "       [-0.25702405,  0.45926246],\n",
       "       [ 1.8680633 , -2.4919705 ],\n",
       "       [-2.4695084 ,  2.8803601 ],\n",
       "       [ 2.512142  , -2.8257148 ],\n",
       "       [ 2.211451  , -2.6471324 ],\n",
       "       [-2.6147501 ,  3.0560086 ],\n",
       "       [ 2.5633972 , -2.8295114 ],\n",
       "       [-2.7145958 ,  3.2370524 ],\n",
       "       [-2.6646636 ,  3.1573877 ],\n",
       "       [-2.6913247 ,  3.2276921 ],\n",
       "       [-2.8326533 ,  3.357219  ],\n",
       "       [-2.6157517 ,  3.0287852 ],\n",
       "       [-2.4019177 ,  2.7956433 ],\n",
       "       [ 0.2210344 ,  0.03373979],\n",
       "       [-2.627512  ,  3.0696983 ],\n",
       "       [ 2.5551248 , -2.9099016 ],\n",
       "       [-2.3290882 ,  2.7741823 ],\n",
       "       [-2.2312832 ,  2.5658984 ],\n",
       "       [ 0.75110054, -0.9884136 ],\n",
       "       [ 2.6491868 , -2.9599032 ],\n",
       "       [ 2.3951883 , -2.7516608 ],\n",
       "       [-2.6929364 ,  3.1687143 ],\n",
       "       [-2.7569358 ,  3.2833393 ],\n",
       "       [-2.5730906 ,  3.0019233 ],\n",
       "       [-2.7205899 ,  3.2670455 ],\n",
       "       [-0.5839986 ,  0.813535  ],\n",
       "       [ 1.2734778 , -1.3773638 ],\n",
       "       [ 2.3897066 , -2.6660657 ],\n",
       "       [-2.777429  ,  3.3125982 ],\n",
       "       [-2.5562088 ,  3.0138385 ],\n",
       "       [-2.7518935 ,  3.280629  ],\n",
       "       [ 2.511154  , -2.867877  ],\n",
       "       [ 2.1982846 , -2.6508667 ],\n",
       "       [-1.7605829 ,  2.0173438 ],\n",
       "       [-2.7603304 ,  3.2911704 ],\n",
       "       [-2.1220021 ,  2.491143  ],\n",
       "       [-2.8059454 ,  3.332373  ],\n",
       "       [-2.81811   ,  3.3243296 ],\n",
       "       [-2.6862693 ,  3.1827338 ],\n",
       "       [ 2.6003554 , -2.7648518 ],\n",
       "       [-2.8109443 ,  3.3382242 ],\n",
       "       [-2.750783  ,  3.2457197 ],\n",
       "       [ 2.2130332 , -2.6455364 ],\n",
       "       [-2.7256653 ,  3.2626479 ],\n",
       "       [ 1.9638261 , -2.4553187 ],\n",
       "       [-2.5064278 ,  2.9098732 ],\n",
       "       [-2.6742303 ,  3.1394901 ],\n",
       "       [-2.8177762 ,  3.3402107 ],\n",
       "       [-2.2423146 ,  2.6540663 ],\n",
       "       [ 2.623919  , -2.8506403 ],\n",
       "       [-2.8121002 ,  3.358937  ],\n",
       "       [ 0.84464157, -1.0585157 ],\n",
       "       [-2.2174366 ,  2.5482118 ],\n",
       "       [-2.7223322 ,  3.2313848 ],\n",
       "       [ 2.5933022 , -2.901301  ],\n",
       "       [ 2.6944673 , -2.9658556 ],\n",
       "       [ 2.6958513 , -2.9501455 ],\n",
       "       [ 2.6107523 , -2.8365774 ],\n",
       "       [ 2.715273  , -3.0128129 ],\n",
       "       [-1.9270337 ,  2.399288  ],\n",
       "       [-1.6445841 ,  2.0908802 ],\n",
       "       [-2.8157883 ,  3.36038   ],\n",
       "       [-1.8860059 ,  2.232628  ],\n",
       "       [-2.8548214 ,  3.391596  ],\n",
       "       [-2.6855383 ,  3.1891358 ],\n",
       "       [-2.1104145 ,  2.493147  ],\n",
       "       [-2.8391786 ,  3.3585153 ],\n",
       "       [-2.80101   ,  3.3233283 ],\n",
       "       [-2.6344876 ,  3.0844715 ],\n",
       "       [-2.6379292 ,  3.130484  ],\n",
       "       [-2.7384422 ,  3.227083  ],\n",
       "       [-2.795967  ,  3.3060064 ],\n",
       "       [-2.6680765 ,  3.2077236 ],\n",
       "       [-2.7753773 ,  3.3024485 ],\n",
       "       [ 1.6250204 , -2.26854   ],\n",
       "       [-2.5844326 ,  2.955776  ],\n",
       "       [-2.775825  ,  3.2856784 ],\n",
       "       [-2.8548133 ,  3.3837745 ],\n",
       "       [ 2.0172875 , -2.4807959 ],\n",
       "       [ 1.4046979 , -1.5154167 ],\n",
       "       [-2.7403572 ,  3.2485614 ],\n",
       "       [-2.803728  ,  3.3366969 ],\n",
       "       [-2.7474675 ,  3.2446644 ],\n",
       "       [-2.7756858 ,  3.3110256 ],\n",
       "       [-2.4620016 ,  2.8465166 ],\n",
       "       [-2.7122746 ,  3.1919754 ],\n",
       "       [ 0.9896698 , -0.8446719 ],\n",
       "       [-2.6969514 ,  3.2086957 ],\n",
       "       [-0.85788566,  1.149813  ],\n",
       "       [-2.7785895 ,  3.2440925 ],\n",
       "       [ 2.3423638 , -2.7268486 ],\n",
       "       [ 1.2725891 , -1.1915221 ],\n",
       "       [-2.6616564 ,  3.1709363 ],\n",
       "       [-2.4782069 ,  2.8958952 ],\n",
       "       [-2.6792405 ,  3.1406898 ],\n",
       "       [-2.5836885 ,  3.0674863 ],\n",
       "       [ 1.6845304 , -2.2943027 ],\n",
       "       [-2.6847644 ,  3.1562586 ],\n",
       "       [-2.8334837 ,  3.368535  ],\n",
       "       [ 0.18797387, -0.0398309 ],\n",
       "       [-2.682358  ,  3.1532166 ],\n",
       "       [-2.8595433 ,  3.4025896 ],\n",
       "       [-2.7363017 ,  3.284289  ],\n",
       "       [-2.3411484 ,  2.6763854 ],\n",
       "       [ 2.0713472 , -2.6304636 ],\n",
       "       [ 1.3049382 , -1.4997932 ],\n",
       "       [-2.5550122 ,  3.012844  ],\n",
       "       [-2.7868068 ,  3.2804866 ],\n",
       "       [-2.7812855 ,  3.3160563 ],\n",
       "       [-0.5930696 ,  0.827481  ],\n",
       "       [ 2.115573  , -2.668119  ],\n",
       "       [ 2.2972045 , -2.6738546 ],\n",
       "       [ 0.32540804, -0.06468897],\n",
       "       [ 2.2955494 , -2.6656458 ],\n",
       "       [-2.6561615 ,  3.1243007 ],\n",
       "       [-2.7100363 ,  3.2007875 ],\n",
       "       [-2.104199  ,  2.5115244 ],\n",
       "       [-2.7914815 ,  3.3152614 ],\n",
       "       [ 1.587738  , -1.5779895 ],\n",
       "       [-2.8248186 ,  3.3707938 ],\n",
       "       [-2.3545656 ,  2.7280703 ],\n",
       "       [ 2.6152453 , -2.9018247 ],\n",
       "       [-2.4570165 ,  2.8985448 ],\n",
       "       [ 1.5086887 , -1.9465623 ],\n",
       "       [-2.7900808 ,  3.3162465 ],\n",
       "       [-2.679208  ,  3.1822648 ],\n",
       "       [-2.785689  ,  3.2905777 ],\n",
       "       [-2.3941514 ,  2.78095   ],\n",
       "       [-2.6926348 ,  3.1664867 ],\n",
       "       [-2.7660992 ,  3.2657976 ],\n",
       "       [-2.6806674 ,  3.1147442 ],\n",
       "       [-2.6444235 ,  3.0703034 ],\n",
       "       [-2.7785017 ,  3.3031964 ],\n",
       "       [ 1.9196018 , -2.094987  ],\n",
       "       [-2.7084243 ,  3.1744545 ],\n",
       "       [-2.7957036 ,  3.32934   ],\n",
       "       [ 2.7631898 , -3.0077329 ],\n",
       "       [-2.8163767 ,  3.3271165 ],\n",
       "       [-0.51351315,  0.6432736 ],\n",
       "       [ 2.040893  , -2.5708761 ],\n",
       "       [-1.4112267 ,  1.8256863 ],\n",
       "       [-2.8406527 ,  3.375739  ],\n",
       "       [ 0.5092683 , -0.14510494],\n",
       "       [-2.5109553 ,  2.93885   ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f330b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0480f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8602941176470589, 'f1': 0.901213171577123}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "956330e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67ee0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", eval_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "135bea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 01:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.580483</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.792968</td>\n",
       "      <td>0.865196</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.810600</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.10356380736905765, metrics={'train_runtime': 65.9627, 'train_samples_per_second': 166.822, 'train_steps_per_second': 20.875, 'total_flos': 405114969714960.0, 'train_loss': 0.10356380736905765, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cfbc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
